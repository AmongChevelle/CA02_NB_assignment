{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4p_DvtT7sOIr",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "# create list_sizes variables with 1000 to 5000 in steps of 500\n",
    "list_sizes = list(range(1000, 3250, 250))\n",
    "for i in list_sizes:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(root_dir, size):\n",
    "    emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #same\n",
    "    # We want to iterate through the emails and create a dictionary of words and the number of times they appear in the emails\n",
    "    dictionary = {}\n",
    "\n",
    "    # For each email:\n",
    "    #     1.  Open email\n",
    "\n",
    "\n",
    "    #     2.  read line\n",
    "\n",
    "\n",
    "    #     3. split line into words\n",
    "\n",
    "\n",
    "    #     4. implement checks to see if word should go into dict\n",
    "\n",
    "    \n",
    "    #     5.  if true, add to dict\n",
    "\n",
    "    for mail in emails:\n",
    "        with open(mail, encoding='latin1') as m:\n",
    "            for line in m:\n",
    "                words = line.lower().split()\n",
    "                for word in words:\n",
    "                    if word.isalpha() and len(word) > 1:\n",
    "                        dictionary[word] = dictionary.get(word, 0) + 1\n",
    "                    else:\n",
    "                        continue\n",
    "    # sort dictionary from highest occurence to lowest NOT using Counter \n",
    "    dictionary = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "    # get most common 3k and return as list\n",
    "    dictionary = dictionary[:size]\n",
    "    dictionary = [i for i in dictionary]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmVW5xNlyOFc",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir, size):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  features_matrix = np.zeros((len(files),size))\n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1;\n",
    "  docID = 0;\n",
    "  # for each file in files\n",
    "  for fil in files:\n",
    "    # open file\n",
    "    with open(fil) as fi:\n",
    "      # read line\n",
    "      for i, line in enumerate(fi):\n",
    "        # split line into words\n",
    "        if i ==2:\n",
    "          words = line.split()\n",
    "          # 0 for each word in words\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "            # for each word in dictionary, ID the word and add to features_matrix\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "      train_labels[docID] = 0;\n",
    "      # filepathTokens = fil.split('/')\n",
    "      # Fix the filepathing issue\n",
    "      filepathTokens = re.split(r'[\\\\/]', fil)\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      # Identify if the email is spam or not and set the labels\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoq-rE7Mx0pp",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "TRAIN_DIR = 'train-mails'\n",
    "TEST_DIR = 'test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a dictionary size of:1000 Accuracy: 0.8961538461538462\n",
      "For a dictionary size of:1250 Accuracy: 0.9615384615384616\n",
      "For a dictionary size of:1500 Accuracy: 0.9615384615384616\n",
      "For a dictionary size of:1750 Accuracy: 0.9807692307692307\n",
      "For a dictionary size of:2000 Accuracy: 0.9730769230769231\n",
      "For a dictionary size of:2250 Accuracy: 0.9730769230769231\n",
      "For a dictionary size of:2500 Accuracy: 0.9615384615384616\n",
      "For a dictionary size of:2750 Accuracy: 0.9615384615384616\n",
      "For a dictionary size of:3000 Accuracy: 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# Iterate through list_sizes and print accuracy and print accuracy for the corresponding list_size\n",
    "for list_size in list_sizes:\n",
    "    dictionary = make_dictionary(TRAIN_DIR, list_size)\n",
    "    features_matrix, labels = extract_features(TRAIN_DIR, list_size)\n",
    "    test_features_matrix, test_labels = extract_features(TEST_DIR, list_size)\n",
    "    # Establish Naive Bayes Model\n",
    "    model = GaussianNB()\n",
    "    # Fit the model\n",
    "    model.fit(features_matrix, labels)\n",
    "    # Predict the labels\n",
    "    predicted_labels = model.predict(test_features_matrix)\n",
    "    # Print the accuracy\n",
    "    print(\"For a dictionary size of:\" + str(list_size) + \" Accuracy:\", accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more granular list of sizes from 1500 to 2000 in steps of 100\n",
    "list_sizes2 = list(range(1500, 2100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a dictionary size of:1500 Accuracy: 0.9615384615384616\n",
      "For a dictionary size of:1600 Accuracy: 0.9769230769230769\n",
      "For a dictionary size of:1700 Accuracy: 0.9730769230769231\n",
      "For a dictionary size of:1800 Accuracy: 0.9769230769230769\n",
      "For a dictionary size of:1900 Accuracy: 0.9692307692307692\n",
      "For a dictionary size of:2000 Accuracy: 0.9730769230769231\n"
     ]
    }
   ],
   "source": [
    "# Iterate through list_sizes and print accuracy for the corresponding list_size\n",
    "for list_size in list_sizes2:\n",
    "    dictionary = make_dictionary(TRAIN_DIR, list_size)\n",
    "    features_matrix, labels = extract_features(TRAIN_DIR, list_size)\n",
    "    test_features_matrix, test_labels = extract_features(TEST_DIR, list_size)\n",
    "    # Establish Naive Bayes model\n",
    "    model = GaussianNB()\n",
    "    # Fit the model\n",
    "    model.fit(features_matrix, labels)\n",
    "    # Predict the labels\n",
    "    predicted_labels = model.predict(test_features_matrix)\n",
    "    # Print the accuracy\n",
    "    print(\"For a dictionary size of:\" + str(list_size) + \" Accuracy:\", accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
